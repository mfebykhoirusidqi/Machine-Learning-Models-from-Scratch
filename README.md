<img width="1536" height="500" alt="Machine learning from scratch Image Nov 3, 2025, 09_54_46 AM" src="https://github.com/user-attachments/assets/56a57b08-6ad4-4b87-92eb-06a705583c62" />
# Machine-Learning-Models-from-Scratch
ğŸ§  Machine Learning Models from Scratch --- This repository demonstrates the mathematical intuition and implementation of essential machine learning algorithms built entirely from scratch using Python and NumPy. The goal is to bridge the gap between theoretical understanding and practical model development â€” showing how core ML algorithms truly work behind the scenes.
âœ¨ By studying and experimenting with this repository, you will gain a solid intuition about how modern AI models build upon these foundational algorithms â€” transforming raw mathematics into intelligent systems.

## ğŸš€ Project Overview
This project aims to rebuild key ML algorithms **without using scikit-learn** â€” focusing on how they work mathematically and programmatically.  
Each model is explained step-by-step through theory, code, and visualization.

### Implemented Models
- ğŸ“ˆ **Linear Regression** â€” Predicting continuous values using gradient descent.
- ğŸ” **Logistic Regression** â€” Binary classification using sigmoid and cost function.
- ğŸ¯ **K-Means Clustering** â€” Unsupervised grouping based on Euclidean distance.

## ğŸ“˜ Notebook Explanation

The notebook [`explanation.ipynb`](src/explanation.ipynb) includes:
- Mathematical formulation and derivation.
- Visual representation of training process.
- Python implementation from scratch.
- Comparison with scikit-learn results

## Demo Result Linier Regression 

<img width="594" height="463" alt="Demo" src="https://github.com/user-attachments/assets/9e63ad39-99dd-4916-8126-d51de832dfb7" />


## â–¶ï¸ Usage

Run any model directly:

- python src/linear_regression.py
- python src/logistic_regression.py
- python src/kmeans.py


Or open the interactive notebook:
jupyter notebook explanation.ipynb


## ğŸ“Š Key Insights

1. Linear Regression shows clear trends fitting with gradient convergence.

2. Logistic Regression demonstrates classification boundaries with sigmoid activation.

3. K-Means visualizes centroid movement and cluster assignment.


## ğŸ§® Mathematical Foundation

This project covers:

1. Gradient Descent Optimization

2. Sigmoid Function and Binary Cross-Entropy

3. Euclidean Distance and Centroid Updates

4. Regression Metrics: MSE, RMSE, RÂ² Score

## ğŸ§‘â€ğŸ’» Author
Muhammad Feby Khoiru Sidqi

Data Angineer | Python Developer | AI Enthusiast | Education Research

 â€¢ ğŸ“§ Email:mfebykhoirus@gmail.com
 â€¢ ğŸŒ LinkedIn : mfebykhoirusidqi
 â€¢ ğŸ GitHub : https://github.com/mfebykhoirusidqi/Machine-Learning-Models-from-Scratch

## â­ Contribute & Support
If you like this project, please â­ star this repository and share it with others.
Contributions, ideas, and suggestions are always welcome!
